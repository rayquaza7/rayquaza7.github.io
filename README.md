Hello! I am a senior at UBC, Vancouver working as a software enginner. I am working on building [drones for mars](https://github.com/mars-robots). I use this website to force myself to concisely lay out my thoughts.

## Mars Drones

---

https://github.com/mars-robots

## Perils of bad, early, wrong, general and too much advice

---

Growing up I watched a LOT of interviews of mostly startup founders, big co ceo's, famous scientists, etc. Most of them tend to give some sort of advice at the end of the interview. Over time I learned that:

- _most_ mistakes they made in hindsight led them to the where they are right now in the first place. Would they have delivered/accomplished what they have if they acted according to their advice from the start? I suspect not.
- internalizing the advice makes you think you are prepared for any situation where you might have to act according to the advice and against your instincts. This can be dangerous, but might give you the confidence to make mistakes you wouldn't otherwise. Dont beat yourself over it too much.
- _most_ advise is given considering an average person in mind.
- too much advice can lead to heuristics and biases in your thinking. This can lead to you evaluating certain things against a criteria that should not exist, is wrong or is not the best for you.
- bad advise may also lead you to think you dont want something you earlier thought you wanted. The show Billions had a pretty good line for this, something along the lines of: Dont imagine what its like to run 2 billion or 5 or 10, just fucking run it. Similarly, don't imagine what its like if you did something, just go do it.

I think the best way to decide if you should listen to any advise is: do a bunch of things, make mistakes, seek out advise, think for yourself, change stuff if necessary.

## Everything is a technology problem

---

[WIP] There are certain things people tend to most likely generalize and influence their decisions or policy. For ex: all dictators bad, 1 university policy for 10,000 students,etc.
I suspect that the cost of framing a policy on an individual basis or evaluating a dictator based on their traits is super expensive relative to the benefits. Moreover, this leads to us taking shortcuts in our thinking and generalizing new situations to fit to our models since the cost of getting information for single instance is hella expensive (neuralink makes it cheaper?).
I also think the cost of these things will fall considerably as ai gets better.

## Electric airplanes

---

I've been obsessed with airplanes since I was a kid and used to admire Boeing. But they've let me down.

- estimated date for a new airplane model is a decade from now
- the 2 737 max crashes showed a lot how the company's culture has become all corporate-y and not focused on engineering like tesla and spacex
- they are not aggresively reducing the complexity of existing airplanes.

I really really believe that this is the perfect time to start an airplane manuffacturing company. start by building an electric business jet that is faster, safer and sexier.
Redesigning a plane also prolly gives you the oppportunity to make it wayyy simpler in terms of number of parts. cater the business jets to people that feel guilty of their carbon emissions + better PR.
once that is setup, start making it bigger.

## How chatgpt changed everything for me lol

---

I used to think I had a mental model for the next 2-5 years, even if it was incredibly abstract, I had something.
That all changed when i used chatgpt. it was fucking magical and i would have never imagined to be using it in 2022.
I had largely ignored ai not knowing what was happening for the past ~5 years.
growth is probably exponential and i suspect i am bad at visualizing how much things change on this curve + i havent been through an exponential (either i dont remember it or wasnt aware of it).
so its prolly wiser to overestimate, if im correct then awesome. if not then doesnt matter since i would have made a lot of progress and done a lot.

## 1,2,3,5,10 year predictions (updated

---
